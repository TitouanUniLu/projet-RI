{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NLP & representation learning: Neural Embeddings, Text Classification\n",
    "\n",
    "\n",
    "To use statistical classifiers with text, it is first necessary to vectorize the text. In the first practical session we explored the **Bag of Word (BoW)** model. \n",
    "\n",
    "Modern **state of the art** methods uses  embeddings to vectorize the text before classification in order to avoid feature engineering.\n",
    "\n",
    "## [Dataset](https://thome.isir.upmc.fr/classes/RITAL/json_pol.json)\n",
    "\n",
    "\n",
    "## \"Modern\" NLP pipeline\n",
    "\n",
    "By opposition to the **bag of word** model, in the modern NLP pipeline everything is **embeddings**. Instead of encoding a text as a **sparse vector** of length $D$ (size of feature dictionnary) the goal is to encode the text in a meaningful dense vector of a small size $|e| <<< |D|$. \n",
    "\n",
    "\n",
    "The raw classification pipeline is then the following:\n",
    "\n",
    "```\n",
    "raw text ---|embedding table|-->  vectors --|Neural Net|--> class \n",
    "```\n",
    "\n",
    "\n",
    "### Using a  language model:\n",
    "\n",
    "How to tokenize the text and extract a feature dictionnary is still a manual task. To directly have meaningful embeddings, it is common to use a pre-trained language model such as `word2vec` which we explore in this practical.\n",
    "\n",
    "In this setting, the pipeline becomes the following:\n",
    "```\n",
    "      \n",
    "raw text ---|(pre-trained) Language Model|--> vectors --|classifier (or fine-tuning)|--> class \n",
    "```\n",
    "\n",
    "\n",
    "- #### Classic word embeddings\n",
    "\n",
    " - [Word2Vec](https://arxiv.org/abs/1301.3781)\n",
    " - [Glove](https://nlp.stanford.edu/projects/glove/)\n",
    "\n",
    "\n",
    "- #### bleeding edge language models techniques (see next)\n",
    "\n",
    " - [UMLFIT](https://arxiv.org/abs/1801.06146)\n",
    " - [ELMO](https://arxiv.org/abs/1802.05365)\n",
    " - [GPT](https://blog.openai.com/language-unsupervised/)\n",
    " - [BERT](https://arxiv.org/abs/1810.04805)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "### Goal of this session:\n",
    "\n",
    "1. Train word embeddings on training dataset\n",
    "2. Tinker with the learnt embeddings and see learnt relations\n",
    "3. Tinker with pre-trained embeddings.\n",
    "4. Use those embeddings for classification\n",
    "5. Compare different embedding models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## STEP 0: Loading data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of reviews :  25000\n",
      "----> # of positive :  12500\n",
      "----> # of negative :  12500\n",
      "\n",
      "['Although credit should have been given to Dr. Seuess for stealing the story-line of \"Horton Hatches The Egg\", this was a fine film. It touched both the emotions and the intellect. Due especially to the incredible performance of seven year old Justin Henry and a script that was sympathetic to each character (and each one\\'s predicament), the thought provoking elements linger long after the tear jerking ones are over. Overall, superior acting from a solid cast, excellent directing, and a very powerful script. The right touches of humor throughout help keep a \"heavy\" subject from becoming tedious or difficult to sit through. Lastly, this film stands the test of time and seems in no way dated, decades after it was released.', 1]\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "from collections import Counter\n",
    "\n",
    "# Loading json\n",
    "file = 'json_pol.json'\n",
    "with open(file,encoding=\"utf-8\") as f:\n",
    "    data = json.load(f)\n",
    "    \n",
    "\n",
    "# Quick Check\n",
    "counter = Counter((x[1] for x in data))\n",
    "print(\"Number of reviews : \", len(data))\n",
    "print(\"----> # of positive : \", counter[1])\n",
    "print(\"----> # of negative : \", counter[0])\n",
    "print(\"\")\n",
    "print(data[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Word2Vec: Quick Recap\n",
    "\n",
    "**[Word2Vec](https://arxiv.org/abs/1301.3781) is composed of two distinct language models (CBOW and SG), optimized to quickly learn word vectors**\n",
    "\n",
    "\n",
    "given a random text: `i'm taking the dog out for a walk`\n",
    "\n",
    "\n",
    "\n",
    "### (a) Continuous Bag of Word (CBOW)\n",
    "    -  predicts a word given a context\n",
    "    \n",
    "maximizing `p(dog | i'm taking the ___ out for a walk)`\n",
    "    \n",
    "### (b) Skip-Gram (SG)               \n",
    "    -  predicts a context given a word\n",
    "    \n",
    " maximizing `p(i'm taking the out for a walk | dog)`\n",
    "\n",
    "\n",
    "\n",
    "   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## STEP 1: train a language model (word2vec)\n",
    "\n",
    "Gensim has one of [Word2Vec](https://radimrehurek.com/gensim/models/word2vec.html) fastest implementation.\n",
    "\n",
    "\n",
    "### Train:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# if gensim not installed yet\n",
    "# ! pip install gensim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-02-07 10:51:25,375 : INFO : collecting all words and their counts\n",
      "2024-02-07 10:51:25,375 : INFO : PROGRESS: at sentence #0, processed 0 words, keeping 0 word types\n",
      "2024-02-07 10:51:26,083 : INFO : PROGRESS: at sentence #10000, processed 2301366 words, keeping 153853 word types\n",
      "2024-02-07 10:51:26,862 : INFO : PROGRESS: at sentence #20000, processed 4553558 words, keeping 240043 word types\n",
      "2024-02-07 10:51:27,246 : INFO : collected 276678 word types from a corpus of 5713167 raw words and 25000 sentences\n",
      "2024-02-07 10:51:27,246 : INFO : Creating a fresh vocabulary\n",
      "2024-02-07 10:51:27,527 : INFO : Word2Vec lifecycle event {'msg': 'effective_min_count=5 retains 48208 unique words (17.42% of original 276678, drops 228470)', 'datetime': '2024-02-07T10:51:27.527456', 'gensim': '4.3.2', 'python': '3.11.7 (tags/v3.11.7:fa7a6f2, Dec  4 2023, 19:24:49) [MSC v.1937 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "2024-02-07 10:51:27,527 : INFO : Word2Vec lifecycle event {'msg': 'effective_min_count=5 leaves 5389596 word corpus (94.34% of original 5713167, drops 323571)', 'datetime': '2024-02-07T10:51:27.527456', 'gensim': '4.3.2', 'python': '3.11.7 (tags/v3.11.7:fa7a6f2, Dec  4 2023, 19:24:49) [MSC v.1937 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "2024-02-07 10:51:27,912 : INFO : deleting the raw counts dictionary of 276678 items\n",
      "2024-02-07 10:51:27,912 : INFO : sample=0.001 downsamples 44 most-common words\n",
      "2024-02-07 10:51:27,912 : INFO : Word2Vec lifecycle event {'msg': 'downsampling leaves estimated 4165010.0598832574 word corpus (77.3%% of prior 5389596)', 'datetime': '2024-02-07T10:51:27.912077', 'gensim': '4.3.2', 'python': '3.11.7 (tags/v3.11.7:fa7a6f2, Dec  4 2023, 19:24:49) [MSC v.1937 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "2024-02-07 10:51:28,571 : INFO : estimated required memory for 48208 words and 100 dimensions: 62670400 bytes\n",
      "2024-02-07 10:51:28,571 : INFO : resetting layer weights\n",
      "2024-02-07 10:51:28,603 : INFO : Word2Vec lifecycle event {'update': False, 'trim_rule': 'None', 'datetime': '2024-02-07T10:51:28.603173', 'gensim': '4.3.2', 'python': '3.11.7 (tags/v3.11.7:fa7a6f2, Dec  4 2023, 19:24:49) [MSC v.1937 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'build_vocab'}\n",
      "2024-02-07 10:51:28,603 : INFO : Word2Vec lifecycle event {'msg': 'training model with 3 workers on 48208 vocabulary and 100 features, using sg=1 hs=0 sample=0.001 negative=5 window=5 shrink_windows=True', 'datetime': '2024-02-07T10:51:28.603173', 'gensim': '4.3.2', 'python': '3.11.7 (tags/v3.11.7:fa7a6f2, Dec  4 2023, 19:24:49) [MSC v.1937 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'train'}\n",
      "2024-02-07 10:51:29,646 : INFO : EPOCH 0 - PROGRESS: at 6.25% examples, 253148 words/s, in_qsize 6, out_qsize 0\n",
      "2024-02-07 10:51:30,669 : INFO : EPOCH 0 - PROGRESS: at 13.05% examples, 263194 words/s, in_qsize 5, out_qsize 0\n",
      "2024-02-07 10:51:31,697 : INFO : EPOCH 0 - PROGRESS: at 20.59% examples, 276862 words/s, in_qsize 5, out_qsize 0\n",
      "2024-02-07 10:51:32,698 : INFO : EPOCH 0 - PROGRESS: at 30.35% examples, 308700 words/s, in_qsize 6, out_qsize 0\n",
      "2024-02-07 10:51:33,716 : INFO : EPOCH 0 - PROGRESS: at 40.94% examples, 334437 words/s, in_qsize 5, out_qsize 0\n",
      "2024-02-07 10:51:34,723 : INFO : EPOCH 0 - PROGRESS: at 51.41% examples, 349251 words/s, in_qsize 5, out_qsize 0\n",
      "2024-02-07 10:51:35,747 : INFO : EPOCH 0 - PROGRESS: at 61.67% examples, 359421 words/s, in_qsize 5, out_qsize 0\n",
      "2024-02-07 10:51:36,747 : INFO : EPOCH 0 - PROGRESS: at 72.02% examples, 368395 words/s, in_qsize 6, out_qsize 0\n",
      "2024-02-07 10:51:37,779 : INFO : EPOCH 0 - PROGRESS: at 82.30% examples, 372814 words/s, in_qsize 6, out_qsize 0\n",
      "2024-02-07 10:51:38,780 : INFO : EPOCH 0 - PROGRESS: at 92.82% examples, 379831 words/s, in_qsize 5, out_qsize 0\n",
      "2024-02-07 10:51:39,496 : INFO : EPOCH 0: training on 5713167 raw words (4165404 effective words) took 10.9s, 382479 effective words/s\n",
      "2024-02-07 10:51:40,513 : INFO : EPOCH 1 - PROGRESS: at 9.84% examples, 411415 words/s, in_qsize 5, out_qsize 0\n",
      "2024-02-07 10:51:41,513 : INFO : EPOCH 1 - PROGRESS: at 20.59% examples, 424535 words/s, in_qsize 5, out_qsize 0\n",
      "2024-02-07 10:51:42,530 : INFO : EPOCH 1 - PROGRESS: at 30.53% examples, 419635 words/s, in_qsize 6, out_qsize 0\n",
      "2024-02-07 10:51:43,530 : INFO : EPOCH 1 - PROGRESS: at 40.38% examples, 417370 words/s, in_qsize 5, out_qsize 0\n",
      "2024-02-07 10:51:44,566 : INFO : EPOCH 1 - PROGRESS: at 50.83% examples, 416732 words/s, in_qsize 6, out_qsize 0\n",
      "2024-02-07 10:51:45,590 : INFO : EPOCH 1 - PROGRESS: at 61.14% examples, 417810 words/s, in_qsize 5, out_qsize 0\n",
      "2024-02-07 10:51:46,596 : INFO : EPOCH 1 - PROGRESS: at 71.46% examples, 419484 words/s, in_qsize 5, out_qsize 0\n",
      "2024-02-07 10:51:47,596 : INFO : EPOCH 1 - PROGRESS: at 81.78% examples, 419214 words/s, in_qsize 5, out_qsize 1\n",
      "2024-02-07 10:51:48,596 : INFO : EPOCH 1 - PROGRESS: at 91.86% examples, 419727 words/s, in_qsize 6, out_qsize 0\n",
      "2024-02-07 10:51:49,412 : INFO : EPOCH 1: training on 5713167 raw words (4164156 effective words) took 9.9s, 420225 effective words/s\n",
      "2024-02-07 10:51:50,452 : INFO : EPOCH 2 - PROGRESS: at 9.30% examples, 377150 words/s, in_qsize 5, out_qsize 0\n",
      "2024-02-07 10:51:51,475 : INFO : EPOCH 2 - PROGRESS: at 19.67% examples, 396674 words/s, in_qsize 5, out_qsize 0\n",
      "2024-02-07 10:51:52,497 : INFO : EPOCH 2 - PROGRESS: at 30.01% examples, 405321 words/s, in_qsize 5, out_qsize 0\n",
      "2024-02-07 10:51:53,514 : INFO : EPOCH 2 - PROGRESS: at 39.34% examples, 400859 words/s, in_qsize 5, out_qsize 0\n",
      "2024-02-07 10:51:54,512 : INFO : EPOCH 2 - PROGRESS: at 49.78% examples, 405869 words/s, in_qsize 5, out_qsize 0\n",
      "2024-02-07 10:51:55,513 : INFO : EPOCH 2 - PROGRESS: at 60.02% examples, 408466 words/s, in_qsize 5, out_qsize 0\n",
      "2024-02-07 10:51:56,523 : INFO : EPOCH 2 - PROGRESS: at 70.12% examples, 410505 words/s, in_qsize 5, out_qsize 0\n",
      "2024-02-07 10:51:57,546 : INFO : EPOCH 2 - PROGRESS: at 80.49% examples, 410730 words/s, in_qsize 5, out_qsize 0\n",
      "2024-02-07 10:51:58,563 : INFO : EPOCH 2 - PROGRESS: at 90.56% examples, 411465 words/s, in_qsize 5, out_qsize 0\n",
      "2024-02-07 10:51:59,489 : INFO : EPOCH 2: training on 5713167 raw words (4165967 effective words) took 10.1s, 413614 effective words/s\n",
      "2024-02-07 10:52:00,512 : INFO : EPOCH 3 - PROGRESS: at 9.84% examples, 406512 words/s, in_qsize 6, out_qsize 0\n",
      "2024-02-07 10:52:01,513 : INFO : EPOCH 3 - PROGRESS: at 20.06% examples, 411299 words/s, in_qsize 5, out_qsize 0\n",
      "2024-02-07 10:52:02,563 : INFO : EPOCH 3 - PROGRESS: at 30.84% examples, 417416 words/s, in_qsize 5, out_qsize 0\n",
      "2024-02-07 10:52:03,592 : INFO : EPOCH 3 - PROGRESS: at 41.61% examples, 423419 words/s, in_qsize 6, out_qsize 0\n",
      "2024-02-07 10:52:04,613 : INFO : EPOCH 3 - PROGRESS: at 52.12% examples, 422044 words/s, in_qsize 5, out_qsize 0\n",
      "2024-02-07 10:52:05,629 : INFO : EPOCH 3 - PROGRESS: at 62.47% examples, 423766 words/s, in_qsize 5, out_qsize 0\n",
      "2024-02-07 10:52:06,629 : INFO : EPOCH 3 - PROGRESS: at 72.74% examples, 423935 words/s, in_qsize 6, out_qsize 0\n",
      "2024-02-07 10:52:07,645 : INFO : EPOCH 3 - PROGRESS: at 83.19% examples, 423546 words/s, in_qsize 5, out_qsize 0\n",
      "2024-02-07 10:52:08,646 : INFO : EPOCH 3 - PROGRESS: at 93.16% examples, 422986 words/s, in_qsize 5, out_qsize 0\n",
      "2024-02-07 10:52:09,313 : INFO : EPOCH 3: training on 5713167 raw words (4163635 effective words) took 9.8s, 423982 effective words/s\n",
      "2024-02-07 10:52:10,335 : INFO : EPOCH 4 - PROGRESS: at 9.83% examples, 404003 words/s, in_qsize 5, out_qsize 0\n",
      "2024-02-07 10:52:11,346 : INFO : EPOCH 4 - PROGRESS: at 20.06% examples, 411077 words/s, in_qsize 5, out_qsize 0\n",
      "2024-02-07 10:52:12,366 : INFO : EPOCH 4 - PROGRESS: at 30.35% examples, 414711 words/s, in_qsize 5, out_qsize 0\n",
      "2024-02-07 10:52:13,378 : INFO : EPOCH 4 - PROGRESS: at 40.58% examples, 416937 words/s, in_qsize 6, out_qsize 0\n",
      "2024-02-07 10:52:14,383 : INFO : EPOCH 4 - PROGRESS: at 50.84% examples, 417302 words/s, in_qsize 6, out_qsize 0\n",
      "2024-02-07 10:52:15,396 : INFO : EPOCH 4 - PROGRESS: at 61.33% examples, 419574 words/s, in_qsize 6, out_qsize 0\n",
      "2024-02-07 10:52:16,412 : INFO : EPOCH 4 - PROGRESS: at 71.67% examples, 420153 words/s, in_qsize 6, out_qsize 0\n",
      "2024-02-07 10:52:17,412 : INFO : EPOCH 4 - PROGRESS: at 81.96% examples, 419720 words/s, in_qsize 5, out_qsize 0\n",
      "2024-02-07 10:52:18,446 : INFO : EPOCH 4 - PROGRESS: at 92.01% examples, 419003 words/s, in_qsize 5, out_qsize 0\n",
      "2024-02-07 10:52:19,225 : INFO : EPOCH 4: training on 5713167 raw words (4164914 effective words) took 9.9s, 420353 effective words/s\n",
      "2024-02-07 10:52:19,225 : INFO : Word2Vec lifecycle event {'msg': 'training on 28565835 raw words (20824076 effective words) took 50.6s, 411380 effective words/s', 'datetime': '2024-02-07T10:52:19.225813', 'gensim': '4.3.2', 'python': '3.11.7 (tags/v3.11.7:fa7a6f2, Dec  4 2023, 19:24:49) [MSC v.1937 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'train'}\n",
      "2024-02-07 10:52:19,225 : INFO : Word2Vec lifecycle event {'params': 'Word2Vec<vocab=48208, vector_size=100, alpha=0.025>', 'datetime': '2024-02-07T10:52:19.225813', 'gensim': '4.3.2', 'python': '3.11.7 (tags/v3.11.7:fa7a6f2, Dec  4 2023, 19:24:49) [MSC v.1937 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'created'}\n"
     ]
    }
   ],
   "source": [
    "import gensim\n",
    "import logging\n",
    "logging.basicConfig(format='%(asctime)s : %(levelname)s : %(message)s', level=logging.INFO)\n",
    "\n",
    "text = [t.split() for t,p in data]\n",
    "\n",
    "# the following configuration is the default configuration\n",
    "w2v = gensim.models.word2vec.Word2Vec(sentences=text,\n",
    "                                vector_size=100, window=5,               ### here we train a cbow model \n",
    "                                min_count=5,                      \n",
    "                                sample=0.001, workers=3,\n",
    "                                sg=1, hs=0, negative=5,        ### set sg to 1 to train a sg model\n",
    "                                cbow_mean=1, epochs=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-02-07 10:52:38,865 : INFO : Word2Vec lifecycle event {'fname_or_handle': 'W2v-movies.dat', 'separately': 'None', 'sep_limit': 10485760, 'ignore': frozenset(), 'datetime': '2024-02-07T10:52:38.865076', 'gensim': '4.3.2', 'python': '3.11.7 (tags/v3.11.7:fa7a6f2, Dec  4 2023, 19:24:49) [MSC v.1937 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'saving'}\n",
      "2024-02-07 10:52:38,867 : INFO : not storing attribute cum_table\n",
      "2024-02-07 10:52:38,998 : INFO : saved W2v-movies.dat\n"
     ]
    }
   ],
   "source": [
    "# Worth it to save the previous embedding\n",
    "w2v.save(\"W2v-movies.dat\")\n",
    "# You will be able to reload them:\n",
    "# w2v = gensim.models.Word2Vec.load(\"W2v-movies.dat\")\n",
    "# and you can continue the learning process if needed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## STEP 2: Test learnt embeddings\n",
    "\n",
    "The word embedding space directly encodes similarities between words: the vector coding for the word \"great\" will be closer to the vector coding for \"good\" than to the one coding for \"bad\". Generally, [cosine similarity](https://en.wikipedia.org/wiki/Cosine_similarity) is the distance used when considering distance between vectors.\n",
    "\n",
    "KeyedVectors have a built in [similarity](https://radimrehurek.com/gensim/models /keyedvectors.html#gensim.models.keyedvectors.BaseKeyedVectors.similarity) method to compute the cosine similarity between words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "great and good: 0.76491594\n",
      "great and bad: 0.4745189\n"
     ]
    }
   ],
   "source": [
    "# is great really closer to good than to bad ?\n",
    "print(\"great and good:\",w2v.wv.similarity(\"great\",\"good\"))\n",
    "print(\"great and bad:\",w2v.wv.similarity(\"great\",\"bad\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since cosine distance encodes similarity, neighboring words are supposed to be similar. The [most_similar](https://radimrehurek.com/gensim/models/keyedvectors.html#gensim.models.keyedvectors.BaseKeyedVectors.most_similar) method returns the `topn` words given a query."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('film', 0.9290799498558044),\n",
       " ('\"movie\"', 0.8077793121337891),\n",
       " ('flick', 0.7757822871208191),\n",
       " ('movie,', 0.7666845321655273),\n",
       " ('dreck', 0.7309340834617615)]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# The query can be as simple as a word, such as \"movie\"\n",
    "\n",
    "# Try changing the word\n",
    "w2v.wv.most_similar(\"movie\",topn=5) # 5 most similar words\n",
    "#w2v.wv.most_similar(\"awesome\",topn=5)\n",
    "#w2v.wv.most_similar(\"actor\",topn=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "But it can be a more complicated query\n",
    "Word embedding spaces tend to encode much more.\n",
    "\n",
    "The most famous exemple is: `vec(king) - vec(man) + vec(woman) => vec(queen)`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('film', 0.7153176665306091),\n",
       " ('\"movie\"', 0.6472780108451843),\n",
       " ('pile', 0.6349601745605469)]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# What is awesome - good + bad ?\n",
    "w2v.wv.most_similar(positive=[\"ugly\",\"movie\"],negative=[\"handsome\"],topn=3)  \n",
    "\n",
    "#w2v.wv.most_similar(positive=[\"actor\",\"woman\"],negative=[\"man\"],topn=3) # do the famous exemple works for actor ?\n",
    "\n",
    "\n",
    "# Try other things like plurals for exemple.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**To test learnt \"synctactic\" and \"semantic\" similarities, Mikolov et al. introduced a special dataset containing a wide variety of three way similarities.**\n",
    "\n",
    "**You can download the dataset [here](https://thome.isir.upmc.fr/classes/RITAL/questions-words.txt).**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-02-07 09:54:41,273 : INFO : Evaluating word analogies for top 300000 words in the model on questions-words.txt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-02-07 09:54:41,568 : INFO : capital-common-countries: 4.4% (4/90)\n",
      "2024-02-07 09:54:41,772 : INFO : capital-world: 0.0% (0/71)\n",
      "2024-02-07 09:54:41,849 : INFO : currency: 0.0% (0/28)\n",
      "2024-02-07 09:54:42,582 : INFO : city-in-state: 0.0% (0/329)\n",
      "2024-02-07 09:54:43,238 : INFO : family: 34.5% (118/342)\n",
      "2024-02-07 09:54:44,950 : INFO : gram1-adjective-to-adverb: 2.0% (19/930)\n",
      "2024-02-07 09:54:45,997 : INFO : gram2-opposite: 2.2% (12/552)\n",
      "2024-02-07 09:54:48,106 : INFO : gram3-comparative: 19.1% (241/1260)\n",
      "2024-02-07 09:54:49,301 : INFO : gram4-superlative: 7.3% (51/702)\n",
      "2024-02-07 09:54:50,420 : INFO : gram5-present-participle: 17.1% (129/756)\n",
      "2024-02-07 09:54:51,515 : INFO : gram6-nationality-adjective: 2.9% (23/792)\n",
      "2024-02-07 09:54:53,233 : INFO : gram7-past-tense: 14.3% (180/1260)\n",
      "2024-02-07 09:54:54,317 : INFO : gram8-plural: 4.8% (39/812)\n",
      "2024-02-07 09:54:55,396 : INFO : gram9-plural-verbs: 28.8% (218/756)\n",
      "2024-02-07 09:54:55,399 : INFO : Quadruplets with out-of-vocabulary words: 55.6%\n",
      "2024-02-07 09:54:55,399 : INFO : NB: analogies containing OOV words were skipped from evaluation! To change this behavior, use \"dummy4unknown=True\"\n",
      "2024-02-07 09:54:55,400 : INFO : Total accuracy: 11.9% (1034/8680)\n"
     ]
    }
   ],
   "source": [
    "out = w2v.wv.evaluate_word_analogies(\"questions-words.txt\",case_insensitive=True)  #original semantic syntactic dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**When training the w2v models on the review dataset, since it hasn't been learnt with a lot of data, it does not perform very well.**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## STEP 3: Loading a pre-trained model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In Gensim, embeddings are loaded and can be used via the [\"KeyedVectors\"](https://radimrehurek.com/gensim/models/keyedvectors.html) class\n",
    "\n",
    "> Since trained word vectors are independent from the way they were trained (Word2Vec, FastText, WordRank, VarEmbed etc), they can be represented by a standalone structure, as implemented in this module.\n",
    "\n",
    ">The structure is called “KeyedVectors” and is essentially a mapping between entities and vectors. Each entity is identified by its string id, so this is a mapping between {str => 1D numpy array}.\n",
    "\n",
    ">The entity typically corresponds to a word (so the mapping maps words to 1D vectors), but for some models, they key can also correspond to a document, a graph node etc. To generalize over different use-cases, this module calls the keys entities. Each entity is always represented by its string id, no matter whether the entity is a word, a document or a graph node.\n",
    "\n",
    "**You can download the pre-trained word embedding [HERE](https://thome.isir.upmc.fr/classes/RITAL/word2vec-google-news-300.dat) .**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-02-07 10:52:54,192 : INFO : loading KeyedVectors object from word2vec-google-news-300.dat\n",
      "2024-02-07 10:52:57,090 : INFO : loading vectors from word2vec-google-news-300.dat.vectors.npy with mmap=None\n",
      "2024-02-07 10:53:02,015 : INFO : KeyedVectors lifecycle event {'fname': 'word2vec-google-news-300.dat', 'datetime': '2024-02-07T10:53:02.015399', 'gensim': '4.3.2', 'python': '3.11.7 (tags/v3.11.7:fa7a6f2, Dec  4 2023, 19:24:49) [MSC v.1937 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'loaded'}\n"
     ]
    }
   ],
   "source": [
    "#from gensim.test.utils import get_tmpfile\n",
    "import gensim.downloader as api\n",
    "from gensim.models import KeyedVectors\n",
    "bload = True\n",
    "fname = \"word2vec-google-news-300\"\n",
    "sdir = \"\" # Change\n",
    "\n",
    "if(bload==True):\n",
    "    wv_pre_trained = KeyedVectors.load(sdir+fname+\".dat\")\n",
    "else:    \n",
    "    wv_pre_trained = api.load(fname)\n",
    "    wv_pre_trained.save(sdir+fname+\".dat\")\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Perform the \"synctactic\" and \"semantic\" evaluations again. Conclude on the pre-trained embeddings.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-02-07 10:24:57,444 : INFO : Evaluating word analogies for top 300000 words in the model on questions-words.txt\n",
      "2024-02-07 10:25:09,370 : INFO : capital-common-countries: 83.2% (421/506)\n",
      "2024-02-07 10:26:20,456 : INFO : capital-world: 81.3% (3552/4368)\n",
      "2024-02-07 10:26:33,436 : INFO : currency: 28.5% (230/808)\n",
      "2024-02-07 10:27:12,555 : INFO : city-in-state: 72.1% (1779/2467)\n",
      "2024-02-07 10:27:20,487 : INFO : family: 86.2% (436/506)\n",
      "2024-02-07 10:27:37,104 : INFO : gram1-adjective-to-adverb: 29.2% (290/992)\n",
      "2024-02-07 10:27:50,769 : INFO : gram2-opposite: 43.5% (353/812)\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[40], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m out \u001b[38;5;241m=\u001b[39m \u001b[43mwv_pre_trained\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mevaluate_word_analogies\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mquestions-words.txt\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43mcase_insensitive\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m#original semantic syntactic dataset.\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\gensim\\models\\keyedvectors.py:1371\u001b[0m, in \u001b[0;36mKeyedVectors.evaluate_word_analogies\u001b[1;34m(self, analogies, restrict_vocab, case_insensitive, dummy4unknown, similarity_function)\u001b[0m\n\u001b[0;32m   1367\u001b[0m predicted \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1368\u001b[0m \u001b[38;5;66;03m# find the most likely prediction using 3CosAdd (vector offset) method\u001b[39;00m\n\u001b[0;32m   1369\u001b[0m \u001b[38;5;66;03m# TODO: implement 3CosMul and set-based methods for solving analogies\u001b[39;00m\n\u001b[1;32m-> 1371\u001b[0m sims \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmost_similar\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpositive\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[43mb\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mc\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnegative\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[43ma\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtopn\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m5\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrestrict_vocab\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrestrict_vocab\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1372\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mkey_to_index \u001b[38;5;241m=\u001b[39m original_key_to_index\n\u001b[0;32m   1373\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m element \u001b[38;5;129;01min\u001b[39;00m sims:\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\gensim\\models\\keyedvectors.py:849\u001b[0m, in \u001b[0;36mKeyedVectors.most_similar\u001b[1;34m(self, positive, negative, topn, clip_start, clip_end, restrict_vocab, indexer)\u001b[0m\n\u001b[0;32m    846\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m indexer \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(topn, \u001b[38;5;28mint\u001b[39m):\n\u001b[0;32m    847\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m indexer\u001b[38;5;241m.\u001b[39mmost_similar(mean, topn)\n\u001b[1;32m--> 849\u001b[0m dists \u001b[38;5;241m=\u001b[39m \u001b[43mdot\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvectors\u001b[49m\u001b[43m[\u001b[49m\u001b[43mclip_start\u001b[49m\u001b[43m:\u001b[49m\u001b[43mclip_end\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmean\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;241m/\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnorms[clip_start:clip_end]\n\u001b[0;32m    850\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m topn:\n\u001b[0;32m    851\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m dists\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "out = wv_pre_trained.evaluate_word_analogies(\"questions-words.txt\",case_insensitive=True)  #original semantic syntactic dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## STEP 4:  sentiment classification\n",
    "\n",
    "In the previous practical session, we used a bag of word approach to transform text into vectors.\n",
    "Here, we propose to try to use word vectors (previously learnt or loaded).\n",
    "\n",
    "\n",
    "### <font color='green'> Since we have only word vectors and that sentences are made of multiple words, we need to aggregate them. </font>\n",
    "\n",
    "\n",
    "### (1) Vectorize reviews using word vectors:\n",
    "\n",
    "Word aggregation can be done in different ways:\n",
    "\n",
    "- Sum\n",
    "- Average\n",
    "- Min/feature\n",
    "- Max/feature\n",
    "\n",
    "#### a few pointers:\n",
    "\n",
    "- `w2v.wv.vocab` is a `set()` of the vocabulary (all existing words in your model)\n",
    "- `np.minimum(a,b) and np.maximum(a,b)` respectively return element-wise min/max "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "\"Key 'a' not present\"",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[21], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m wv_pre_trained\u001b[38;5;241m.\u001b[39mindex_to_key\n\u001b[1;32m----> 2\u001b[0m \u001b[43mwv_pre_trained\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43ma\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241m.\u001b[39mshape\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\gensim\\models\\keyedvectors.py:403\u001b[0m, in \u001b[0;36mKeyedVectors.__getitem__\u001b[1;34m(self, key_or_keys)\u001b[0m\n\u001b[0;32m    389\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Get vector representation of `key_or_keys`.\u001b[39;00m\n\u001b[0;32m    390\u001b[0m \n\u001b[0;32m    391\u001b[0m \u001b[38;5;124;03mParameters\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    400\u001b[0m \n\u001b[0;32m    401\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    402\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(key_or_keys, _KEY_TYPES):\n\u001b[1;32m--> 403\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_vector\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey_or_keys\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    405\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m vstack([\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mget_vector(key) \u001b[38;5;28;01mfor\u001b[39;00m key \u001b[38;5;129;01min\u001b[39;00m key_or_keys])\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\gensim\\models\\keyedvectors.py:446\u001b[0m, in \u001b[0;36mKeyedVectors.get_vector\u001b[1;34m(self, key, norm)\u001b[0m\n\u001b[0;32m    422\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mget_vector\u001b[39m(\u001b[38;5;28mself\u001b[39m, key, norm\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m):\n\u001b[0;32m    423\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Get the key's vector, as a 1D numpy array.\u001b[39;00m\n\u001b[0;32m    424\u001b[0m \n\u001b[0;32m    425\u001b[0m \u001b[38;5;124;03m    Parameters\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    444\u001b[0m \n\u001b[0;32m    445\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 446\u001b[0m     index \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_index\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    447\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m norm:\n\u001b[0;32m    448\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfill_norms()\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\gensim\\models\\keyedvectors.py:420\u001b[0m, in \u001b[0;36mKeyedVectors.get_index\u001b[1;34m(self, key, default)\u001b[0m\n\u001b[0;32m    418\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m default\n\u001b[0;32m    419\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 420\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mKey \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mkey\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m not present\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[1;31mKeyError\u001b[0m: \"Key 'a' not present\""
     ]
    }
   ],
   "source": [
    "wv_pre_trained.index_to_key\n",
    "wv_pre_trained[\"a\"].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-193.06982422  125.63803101  -13.10174561  151.31201172  -55.65597534\n",
      "   29.10305786  -99.427948    -58.08508301  -44.15045166   25.18914795\n",
      "  -64.50530243  -94.73694611 -233.42119789   16.89067459 -135.52319336\n",
      "  106.13586426  113.6817627   194.2935791   -19.74264526    2.78518677\n",
      " -277.12670898  -39.00292969  136.7069931    20.926754    -96.63015747\n",
      "   32.47764301 -281.21362305   59.47219849  -33.52801514  -19.21615601\n",
      "    2.21058655   40.76168823  -67.97140503 -113.81192017 -148.85321045\n",
      "  104.91274261 -229.38604736  133.80688477  -59.29985428   94.09295654\n",
      "  -43.86633301  -54.90148926   87.67941284   98.87811279   58.91075325\n",
      "  -44.13633919  -45.1319046  -198.18295288 -125.19122314   91.4576416\n",
      " -196.48156738  266.33451843  -36.92724609  263.26843262   54.03488731\n",
      "  139.2162323  -167.81604004 -102.33627319   -5.06425476 -179.14355469\n",
      " -149.18780518  -81.51074219 -206.20321655  -60.93465137  -40.14211273\n",
      " -224.79187012 -114.6053772   126.20214844  -63.78582764   58.89859772\n",
      "   36.05225825  -61.82850647   45.26611328   -3.931427    -49.03917027\n",
      "  -12.58459473  143.3760376    25.54711914    8.98139954  -96.59240723\n",
      " -153.93322754  -15.73457813  -35.35645676   -6.32313538  135.7175293\n",
      "   79.03839111  -17.95281982  242.32397461   12.66809082   60.72279358\n",
      "   12.60583496   30.8918457   -31.04893494 -144.97190857   47.69366455\n",
      "  114.67619324  -94.16555405  112.10748291  283.24780273  -31.35735321\n",
      " -103.24492645  -15.33081055  -73.51196289  -12.96253204  -71.86102295\n",
      "  160.31130981  -83.80096436   47.42779541  -14.77856445   19.51834106\n",
      " -159.91943359 -190.66976929  -26.73154449  -45.11190796   77.75629425\n",
      "  173.56719971   87.98448563  -45.64917612  -30.10401917  -38.60805511\n",
      "  122.12158203   76.88067627   -7.32570648   27.97998047  130.23950195\n",
      " -182.17016602 -112.53019714  -30.39306641   58.22253418  111.83148193\n",
      " -102.08297729  -25.61911011  -78.28582764  -45.89343262 -183.89426422\n",
      "   85.20145416  -49.60753632   32.47263336  271.82070923  152.75151062\n",
      "  209.39343262  -77.41531372   48.58318329  -43.57556152  -62.82287598\n",
      " -101.29782486  -69.16906738  169.8684082   -57.4864502    34.76870728\n",
      "   85.30706787 -334.34094238  -52.64398003  -53.20083618 -122.43199158\n",
      "  -91.24768066   87.24153137  195.39241791  -36.87965393  -38.39816284\n",
      "   17.83774185   94.74517822   -6.96160889   17.02706909  -12.11126709\n",
      "  -61.55731201  175.06860352   33.42034912 -106.55800629  105.83618164\n",
      " -130.61434937  -92.27929688  -38.15365601  -74.01071167  -16.95526123\n",
      "  236.7395401   273.92773438 -227.16552734   20.36761475  -89.96107483\n",
      "    9.2952888    34.50263977   46.26394653  -54.67779541  -25.31994247\n",
      "   80.72283936  -57.37304688   77.68232727  -36.67985535   46.85980988\n",
      "  130.96589661  -40.94482422 -271.07531738  -20.33511353  131.50952148\n",
      "   45.24780273  -79.13371277  -23.28689575   75.45645142 -100.02380371\n",
      " -120.77783203   20.30377197 -226.99865723 -142.78991699   84.29417419\n",
      "  -82.42221069  -37.23120117  106.8666153   -48.21461487  180.65600586\n",
      "  158.97244263  104.43838501 -164.34365845   -0.48170471  -99.45251465\n",
      "   36.89358902  172.24728394  -82.29256439 -179.00619507   13.1953125\n",
      " -149.45858765  154.17803955   66.8326416    -9.42802429    5.79486084\n",
      " -100.83410645   80.83769989   66.64262962   -6.05279541 -154.37158203\n",
      "   32.86367798  -67.65047455 -102.20024872   19.08930969   12.49710083\n",
      "   22.92674065   48.24986267  109.05496216  103.24689102  106.41316223\n",
      "   99.40628052   99.19846344  312.43200684  -64.48757935  -18.05426788\n",
      "   93.02783203 -172.07318115  173.36236572   44.49474502  -92.26245117\n",
      "   83.82858658   25.97198486   72.49575806  115.01138306  -12.99603271\n",
      " -141.20581055  -43.92422485   67.05584717   30.50390625  -78.20535278\n",
      "   93.3966217   -14.78326607  103.1231842   -23.7973938   -97.95787811\n",
      "   24.78585815   -8.11883545   14.72503662  -16.46333313  -61.88450623\n",
      "  -86.71363831  -17.12153244   51.58581543   33.78881836   86.74468994\n",
      "  -83.42926025 -177.15484619 -154.16821289 -112.06201172   69.00494385\n",
      " -106.9352417   161.94681549    5.09896851   12.56838989    8.33114624\n",
      "   63.8192749   -12.07839966  -31.72904205  -63.61303711  -40.35543823\n",
      "   72.45452881    6.51391602  -94.93305969  104.32263184  -39.09408569\n",
      " -178.1426239  -113.95581055  -34.84063721 -123.70776749  153.3236084 ]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "# We first need to vectorize text:\n",
    "# First we propose to a sum of them\n",
    "\n",
    "def vectorize(text,mean=False):\n",
    "    \"\"\"\n",
    "    This function should vectorize one review\n",
    "\n",
    "    input: str\n",
    "    output: np.array(float)\n",
    "    \"\"\"    \n",
    "    vec=np.zeros(wv_pre_trained[\"the\"].shape)\n",
    "    for word in text:\n",
    "        if word in wv_pre_trained:\n",
    "            vec+=wv_pre_trained[word]\n",
    "    \n",
    "            \n",
    "    return vec\n",
    "    \n",
    "train,test=train_test_split(data,test_size=0.2,train_size=0.8)\n",
    "classes = [pol for text,pol in train]\n",
    "X = [vectorize(text) for text,pol in train]\n",
    "X_test = [vectorize(text) for text,pol in test]\n",
    "true = [pol for text,pol in test]\n",
    "\n",
    "#let's see what a review vector looks like.\n",
    "print(X[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (2) Train a classifier \n",
    "as in the previous practical session, train a logistic regression to do sentiment classification with word vectors\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.6488\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hatem\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\linear_model\\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "classifier=LogisticRegression(max_iter=10000)\n",
    "classifier.fit(X,classes)\n",
    "y_pred=classifier.predict(X_test)\n",
    "accuracy=accuracy_score(true,y_pred)\n",
    "\n",
    "print(\"Accuracy:\", accuracy)\n",
    "\n",
    "# Scikit Logistic Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "performance should be worst than with bag of word (~80%). Sum/Mean aggregation does not work well on long reviews (especially with many frequent words). This adds a lot of noise.\n",
    "\n",
    "## **Todo** :  Try answering the following questions:\n",
    "\n",
    "- Which word2vec model works best: skip-gram or cbow\n",
    "- Do pretrained vectors work best than those learnt on the train dataset ?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "**(Bonus)** To have a better accuracy, we could try two things:\n",
    "- Better aggregation methods (weight by tf-idf ?)\n",
    "- Another word vectorizing method such as [fasttext](https://radimrehurek.com/gensim/models/fasttext.html)\n",
    "- A document vectorizing method such as [Doc2Vec](https://radimrehurek.com/gensim/models/doc2vec.html)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  },
  "vscode": {
   "interpreter": {
    "hash": "902a52bcf4503a473db011f1937bdfe17613b08622219712e0110e48c4958c23"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
