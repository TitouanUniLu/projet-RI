{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import codecs\n",
    "import re\n",
    "import os.path"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Données reconnaissance du locuteur (Chirac/Mitterrand)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Chargement des données:\n",
    "def load_pres(fname):\n",
    "    alltxts = []\n",
    "    alllabs = []\n",
    "    s=codecs.open(fname, 'r','utf-8') # pour régler le codage\n",
    "    while True:\n",
    "        txt = s.readline()\n",
    "        if(len(txt))<5:\n",
    "            break\n",
    "        #\n",
    "        lab = re.sub(r\"<[0-9]*:[0-9]*:(.)>.*\",\"\\\\1\",txt)\n",
    "        txt = re.sub(r\"<[0-9]*:[0-9]*:.>(.*)\",\"\\\\1\",txt)\n",
    "        if lab.count('M') >0:\n",
    "            alllabs.append(-1)\n",
    "        else: \n",
    "            alllabs.append(1)\n",
    "        alltxts.append(txt)\n",
    "    return alltxts,alllabs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "fname = \"./datasets/AFDpresidentutf8/corpus.tache1.learn.utf8\"\n",
    "alltxts,alllabs = load_pres(fname)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "57413 57413\n",
      " Quand je dis chers amis, il ne s'agit pas là d'une formule diplomatique, mais de l'expression de ce que je ressens.\n",
      "\n",
      "1\n",
      " Je compte sur vous.\n",
      "\n",
      "1\n"
     ]
    }
   ],
   "source": [
    "print(len(alltxts),len(alllabs))\n",
    "print(alltxts[0])\n",
    "print(alllabs[0])\n",
    "print(alltxts[-1])\n",
    "print(alllabs[-1])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Données classification de sentiments (films)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_movies(path2data): # 1 classe par répertoire\n",
    "    alltxts = [] # init vide\n",
    "    labs = []\n",
    "    cpt = 0\n",
    "    for cl in os.listdir(path2data): # parcours des fichiers d'un répertoire\n",
    "        for f in os.listdir(path2data+cl):\n",
    "            txt = open(path2data+cl+'/'+f).read()\n",
    "            alltxts.append(txt)\n",
    "            labs.append(cpt)\n",
    "        cpt+=1 # chg répertoire = cht classe\n",
    "        \n",
    "    return alltxts,labs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = \"./datasets/movies/movies1000/\"\n",
    "\n",
    "alltxts_mov,alllabs_mov = load_movies(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2000 2000\n",
      "plot : two teen couples go to a church party , drink and then drive . \n",
      "they get into an accident . \n",
      "one of the guys dies , but his girlfriend continues to see him in her life , and has nightmares . \n",
      "what's the deal ? \n",
      "watch the movie and \" sorta \" find out . . . \n",
      "critique : a mind-fuck movie for the teen generation that touches on a very cool idea , but presents it in a very bad package . \n",
      "which is what makes this review an even harder one to write , since i generally applaud films which attempt to break the mold , mess with your head and such ( lost highway & memento ) , but there are good and bad ways of making all types of films , and these folks just didn't snag this one correctly . \n",
      "they seem to have taken this pretty neat concept , but executed it terribly . \n",
      "so what are the problems with the movie ? \n",
      "well , its main problem is that it's simply too jumbled . \n",
      "it starts off \" normal \" but then downshifts into this \" fantasy \" world in which you , as an audience member , have no idea what's going on . \n",
      "there are dreams , there are characters coming back from the dead , there are others who look like the dead , there are strange apparitions , there are disappearances , there are a looooot of chase scenes , there are tons of weird things that happen , and most of it is simply not explained . \n",
      "now i personally don't mind trying to unravel a film every now and then , but when all it does is give me the same clue over and over again , i get kind of fed up after a while , which is this film's biggest problem . \n",
      "it's obviously got this big secret to hide , but it seems to want to hide it completely until its final five minutes . \n",
      "and do they make things entertaining , thrilling or even engaging , in the meantime ? \n",
      "not really . \n",
      "the sad part is that the arrow and i both dig on flicks like this , so we actually figured most of it out by the half-way point , so all of the strangeness after that did start to make a little bit of sense , but it still didn't the make the film all that more entertaining . \n",
      "i guess the bottom line with movies like this is that you should always make sure that the audience is \" into it \" even before they are given the secret password to enter your world of understanding . \n",
      "i mean , showing melissa sagemiller running away from visions for about 20 minutes throughout the movie is just plain lazy ! ! \n",
      "okay , we get it . . . there \n",
      "are people chasing her and we don't know who they are . \n",
      "do we really need to see it over and over again ? \n",
      "how about giving us different scenes offering further insight into all of the strangeness going down in the movie ? \n",
      "apparently , the studio took this film away from its director and chopped it up themselves , and it shows . \n",
      "there might've been a pretty decent teen mind-fuck movie in here somewhere , but i guess \" the suits \" decided that turning it into a music video with little edge , would make more sense . \n",
      "the actors are pretty good for the most part , although wes bentley just seemed to be playing the exact same character that he did in american beauty , only in a new neighborhood . \n",
      "but my biggest kudos go out to sagemiller , who holds her own throughout the entire film , and actually has you feeling her character's unraveling . \n",
      "overall , the film doesn't stick because it doesn't entertain , it's confusing , it rarely excites and it feels pretty redundant for most of its runtime , despite a pretty cool ending and explanation to all of the craziness that came before it . \n",
      "oh , and by the way , this is not a horror or teen slasher flick . . . it's \n",
      "just packaged to look that way because someone is apparently assuming that the genre is still hot with the kids . \n",
      "it also wrapped production two years ago and has been sitting on the shelves ever since . \n",
      "whatever . . . skip \n",
      "it ! \n",
      "where's joblo coming from ? \n",
      "a nightmare of elm street 3 ( 7/10 ) - blair witch 2 ( 7/10 ) - the crow ( 9/10 ) - the crow : salvation ( 4/10 ) - lost highway ( 10/10 ) - memento ( 10/10 ) - the others ( 9/10 ) - stir of echoes ( 8/10 ) \n",
      "\n",
      "0\n",
      "truman ( \" true-man \" ) burbank is the perfect name for jim carrey's character in this film . \n",
      "president truman was an unassuming man who became known worldwide , in spite of ( or was it because of ) his stature . \n",
      " \" truman \" also recalls an era of plenty following a grim war , an era when planned communities built by government scientists promised an idyllic life for americans . \n",
      "and burbank , california , brings to mind the tonight show and the home of nbc . \n",
      "if hollywood is the center of the film world , burbank is , or was , the center of tv's world , the world where our protagonist lives . \n",
      "combine all these names and concepts into \" truman burbank , \" and you get something that well describes him and his artificial world . \n",
      "truman leads the perfect life . \n",
      "his town , his car , and his wife are picture perfect . \n",
      "his idea of reality comes under attack one day when a studio light falls from the sky . \n",
      "the radio explains that an overflying airplane started coming apart . \n",
      " . \n",
      " . \n",
      "but then why would an airplane be carrying a studio light ? \n",
      "the next day during the drive to work , the radio jams and he starts picking up a voice that exactly describes his movements . \n",
      "he is so distracted that he nearly hits a pedestrian . \n",
      "when the radio comes back to normal , the announcer warns listeners to drive carefully . \n",
      "his suspicion aroused , he wanders around the town square looking for other oddities . \n",
      "the world appears to be functioning properly until he enters an office building and tries to take the elevator . \n",
      "the elevator doors open up on a small lounge with people on coffee breaks . \n",
      "a grip sees truman him and quickly moves a paneled door , made to look like the back of an elevator , into place . \n",
      "two security guards grab him and throw him out . \n",
      "truman is really suspicious now . \n",
      "it gets even worse the next day when his wife , a nurse , describes an elevator accident in the building where he saw the lounge . \n",
      " \" it's best not to think about it , \" she says , trying vainly to change truman's memory . \n",
      "truman becomes determined to see who or what is behind this apparently elaborate hoax at his expense . \n",
      "at every turn he is stopped by an amazing coincidence that just happens to keep him in his own little town . \n",
      "his last hope is to quell his fear of the ocean and sail to the edge of the world . \n",
      "you know by now that truman's life is the subject of a television program . \n",
      "his actions are \" real \" but everything else is carefully scripted , from the death of his father to the choice of his wife . \n",
      "truman is determined to find out what the big hoax is . \n",
      "meanwhile , christof , the all-seeing creator of truman's world does his best to keep him unaware and happy . \n",
      "it's sort of like westworld told from the robots' point of view , or jurassic park from the dinosaurs' point of view . \n",
      "we root for the captive of the cage-world . \n",
      "our protagonist is counting on \" chaos theory \" to help him escape his elaborate trap . \n",
      "the story , written by andrew niccol ( writer/director of gattaca ) , introduces some interesting questions , such as the ethics of subjecting a person to this type of life , or the psychological impact of learning that your entire life has all been fake . \n",
      "although these questions came to mind , i don't think the film itself asked them . \n",
      "it certainly didn't address them or try to answer them . \n",
      "i was particularly disappointed that the film didn't deal more with the trauma of learning one's life is a tv show . \n",
      "carrey's performance at the end showed a smidgen of truman's pain , but i almost felt that he got over it too easily for the sake of the film's pacing . \n",
      "earlier in the movie i found myself wondering if it would be better for truman to find out the truth or whether i should root for him to be well . \n",
      "the two seemed exclusive of one another , but weir and niccol didn't see it that way . \n",
      "perhaps it's not fair to criticize a movie for what it isn't , but it seems like there were some missed opportunities here . \n",
      "but on its own terms , the movie is well made . \n",
      "sight , sound and pacing are all handled competently . \n",
      "much of the first part of the movie is the truman show . \n",
      "the scenes are all apparently shot from hidden cameras , with snoots and obstructions covering the corners of the screen . \n",
      "one hidden camera is apparently in his car radio , the green led numbers obscuring the lower part of the screen . \n",
      "the music is well-chosen and scored . \n",
      "the film opens with what sounds like family drama theme music , when truman's world is still beautiful and perfect . \n",
      "when the movie ends , the score sounds more like a frantic , driven , tangerine dream opus , while still keeping the same timbre . \n",
      "philip glass' epic music ( from powaqqatsi ) permeates truman's scenes of suspicion and awakening . \n",
      " ( glass has a small cameo as a keyboardist for the show . ) \n",
      "and the pacing of the story was brisk . \n",
      "there was no unnecessarily long setup explaining the concept behind the truman show , just a few quick title cards , a few interviews , and then right into the show , and the movie . \n",
      "one of the first scenes is of the studio light falling ; there was no token scene of truman's idyllic life before it falls apart , because it wasn't necessary , we pick up the story at the first sign of trouble , and no sooner . \n",
      "there's also no point in the movie where the plot slows down . \n",
      "it's a quick , straight shot to the movie's end . \n",
      "in terms of overall quality , i would compare the truman show to niccol's gattaca . \n",
      "both films are well made with interesting stories set in interesting worlds . \n",
      "but neither film really felt like it capitalized on all the great ideas ; neither film \" clicked \" and became an instant classic . \n",
      "nevertheless , i look forward to niccol's next film , whatever it may be . \n",
      "\n",
      "1\n"
     ]
    }
   ],
   "source": [
    "print(len(alltxts_mov),len(alllabs_mov))\n",
    "print(alltxts_mov[0])\n",
    "print(alllabs_mov[0])\n",
    "print(alltxts_mov[-1])\n",
    "print(alllabs_mov[-1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# A) Transformation paramétrique du texte (pre-traitements)\n",
    "\n",
    "Vous devez tester, par exemple, les cas suivants:\n",
    "- transformation en minuscule ou pas\n",
    "- suppression de la ponctuation\n",
    "- transformation des mots entièrement en majuscule en marqueurs spécifiques\n",
    "- suppression des chiffres ou pas\n",
    "- conservation d'une partie du texte seulement (seulement la première ligne = titre, seulement la dernière ligne = résumé, ...)\n",
    "- stemming\n",
    "- ...\n",
    "\n",
    "\n",
    "Vérifier systématiquement sur un exemple ou deux le bon fonctionnement des méthodes sur deux documents (au moins un de chaque classe)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original:\n",
      "\n",
      "class: 1 , texte:  Quand je dis chers amis, il ne s'agit pas là d'une formule diplomatique, mais de l'expression de ce que je ressens.\n",
      "\n",
      "\n",
      "class: -1 , texte:  Je ne sais ni pourquoi ni comment on s'est opposé il y a quelques douze années - douze ou treize ans - à la création de l'Université technologique.\n",
      "\n",
      "Processed:\n",
      "\n",
      "class: 1 , texte: quand je dis cher amis il ne s agit pas la d une formul diplomat mais de l express de ce que je ressen\n",
      "\n",
      "class: -1 , texte: je ne sais ni pourquoi ni comment on s est oppos il y a quelqu douz anne douz ou treiz an a la creation de l universit technolog\n"
     ]
    }
   ],
   "source": [
    "import string \n",
    "import unicodedata\n",
    "import nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem.snowball import FrenchStemmer\n",
    "\n",
    "punc = string.punctuation \n",
    "punc += '\\n\\r\\t'\n",
    "stemmer = FrenchStemmer()\n",
    "\n",
    "print('Original:')\n",
    "print(f'\\nclass: {alllabs[0]} , texte: {alltxts[0]}')\n",
    "print(f'\\nclass: {alllabs[11]} , texte: {alltxts[11]}')\n",
    "for i in range(0,len(alltxts)):\n",
    "    #alltxts[i] = re.sub('[0-9]+', '', alltxts[i]) #a garder ou enlever\n",
    "    alltxts[i] = alltxts[i].lower() \n",
    "    alltxts[i] = alltxts[i].translate(str.maketrans(punc, ' ' * len(punc))) #ponctuation\n",
    "    alltxts[i] = unicodedata.normalize('NFD', alltxts[i]).encode('ascii', 'ignore').decode(\"utf-8\") #normalize en unicode, enleve non ascii et reconvertir en utf 8\n",
    "    words = word_tokenize(alltxts[i], language='french')\n",
    "    stemmed = [stemmer.stem(word) for word in words]\n",
    "    alltxts[i] = ' '.join(stemmed)\n",
    "\n",
    "print('Processed:')\n",
    "print(f'\\nclass: {alllabs[0]} , texte: {alltxts[0]}')\n",
    "print(f'\\nclass: {alllabs[11]} , texte: {alltxts[11]}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# B) Extraction du vocabulaire (BoW)\n",
    "\n",
    "- **Exploration préliminaire des jeux de données**\n",
    "    - Quelle est la taille d'origine du vocabulaire?\n",
    "    - Que reste-t-il si on ne garde que les 100 mots les plus fréquents? [word cloud]\n",
    "    - Quels sont les 100 mots dont la fréquence documentaire est la plus grande? [word cloud]\n",
    "    - Quels sont les 100 mots les plus discriminants au sens de odds ratio? [word cloud]\n",
    "    - Quelle est la distribution d'apparition des mots (Zipf)\n",
    "    - Quels sont les 100 bigrammes/trigrammes les plus fréquents?\n",
    "\n",
    "- **Variantes de BoW**\n",
    "    - TF-IDF\n",
    "    - Réduire la taille du vocabulaire (min_df, max_df, max_features)\n",
    "    - BoW binaire\n",
    "    - Bi-grams, tri-grams\n",
    "    - **Quelles performances attendre ? Quels sont les avantages et les inconvénients des ces variantes?**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(57413, 28524)\n"
     ]
    },
    {
     "ename": "NotFittedError",
     "evalue": "Vocabulary not fitted or provided",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNotFittedError\u001b[0m                            Traceback (most recent call last)",
      "Input \u001b[1;32mIn [26]\u001b[0m, in \u001b[0;36m<cell line: 8>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     10\u001b[0m vectorized \u001b[38;5;241m=\u001b[39m vectorizer_p\u001b[38;5;241m.\u001b[39mfit_transform(db)\n\u001b[0;32m     11\u001b[0m \u001b[38;5;28mprint\u001b[39m(vectorized\u001b[38;5;241m.\u001b[39mshape)\n\u001b[1;32m---> 12\u001b[0m features \u001b[38;5;241m=\u001b[39m \u001b[43mvectorizer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_feature_names_out\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     13\u001b[0m vocab \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(features)\n\u001b[0;32m     14\u001b[0m top_words_indices \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39margsort(vectorizer\u001b[38;5;241m.\u001b[39midf_)[::\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m][:\u001b[38;5;241m100\u001b[39m] \n",
      "File \u001b[1;32mc:\\Users\\titouan\\anaconda3\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:1446\u001b[0m, in \u001b[0;36mCountVectorizer.get_feature_names_out\u001b[1;34m(self, input_features)\u001b[0m\n\u001b[0;32m   1433\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mget_feature_names_out\u001b[39m(\u001b[38;5;28mself\u001b[39m, input_features\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[0;32m   1434\u001b[0m     \u001b[38;5;124;03m\"\"\"Get output feature names for transformation.\u001b[39;00m\n\u001b[0;32m   1435\u001b[0m \n\u001b[0;32m   1436\u001b[0m \u001b[38;5;124;03m    Parameters\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1444\u001b[0m \u001b[38;5;124;03m        Transformed feature names.\u001b[39;00m\n\u001b[0;32m   1445\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m-> 1446\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_check_vocabulary\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1447\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m np\u001b[38;5;241m.\u001b[39masarray(\n\u001b[0;32m   1448\u001b[0m         [t \u001b[38;5;28;01mfor\u001b[39;00m t, i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28msorted\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mvocabulary_\u001b[38;5;241m.\u001b[39mitems(), key\u001b[38;5;241m=\u001b[39mitemgetter(\u001b[38;5;241m1\u001b[39m))],\n\u001b[0;32m   1449\u001b[0m         dtype\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mobject\u001b[39m,\n\u001b[0;32m   1450\u001b[0m     )\n",
      "File \u001b[1;32mc:\\Users\\titouan\\anaconda3\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:498\u001b[0m, in \u001b[0;36m_VectorizerMixin._check_vocabulary\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    496\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_validate_vocabulary()\n\u001b[0;32m    497\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfixed_vocabulary_:\n\u001b[1;32m--> 498\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m NotFittedError(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mVocabulary not fitted or provided\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    500\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mvocabulary_) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m    501\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mVocabulary is empty\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[1;31mNotFittedError\u001b[0m: Vocabulary not fitted or provided"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer,TfidfVectorizer\n",
    "\n",
    "vectorizer_p = TfidfVectorizer()\n",
    "vectorizer_m = TfidfVectorizer()\n",
    "\n",
    "#print(type(alltxts))\n",
    "\n",
    "for db in [alltxts, alltxts_mov]:\n",
    "    vectorizer = TfidfVectorizer()\n",
    "    vectorized = vectorizer_p.fit_transform(db)\n",
    "    print(vectorized.shape)\n",
    "    features = vectorizer.get_feature_names_out()\n",
    "    vocab = len(features)\n",
    "    top_words_indices = np.argsort(vectorizer.idf_)[::-1][:100] \n",
    "    top_words = [features[i] for i in top_words_indices]\n",
    "    print(\"100 mots les plus frequents\")\n",
    "    print(top_words)\n",
    "\n",
    "\n",
    "\n",
    "'''\n",
    "print(np.argmax(presidents.toarray()[0])) #indice du mot avec le idf le plus fort dans le premier message\n",
    "print(vectorizer_p.get_feature_names_out()[np.argmax(presidents.toarray()[0])]) #mot du print precedent'''\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# C) Modèles de Machine Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1) Métriques d'évaluation \n",
    "\n",
    "Il faudra utiliser des métriques d'évaluation pertinentes suivant la tâche et l'équilibrage des données : \n",
    "- Accuracy\n",
    "- Courbe ROC, AUC, F1-score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2) Variantes sur les stratégies d'entraînement\n",
    "\n",
    "- **Sur-apprentissage**. Les techniques sur lesquelles nous travaillons étant sujettes au sur-apprentissage: trouver le paramètre de régularisation dans la documentation et optimiser ce paramètre au sens de la métrique qui vous semble la plus appropriée (cf question précédente).\n",
    "\n",
    " <br>\n",
    "- **Equilibrage des données**. Un problème reconnu comme dur dans la communauté est celui de l'équilibrage des classes (*balance* en anglais). Que faire si les données sont à 80, 90 ou 99% dans une des classes?\n",
    "Le problème est dur mais fréquent; les solutions sont multiples mais on peut isoler 3 grandes familles de solution.\n",
    "\n",
    "1. Ré-équilibrer le jeu de données: supprimer des données dans la classe majoritaire et/ou sur-échantilloner la classe minoritaire.<BR>\n",
    "   $\\Rightarrow$ A vous de jouer pour cette technique\n",
    "1. Changer la formulation de la fonction de coût pour pénaliser plus les erreurs dans la classe minoritaire:\n",
    "soit une fonction $\\Delta$ mesurant les écarts entre $f(x_i)$ et $y_i$ \n",
    "$$C = \\sum_i  \\alpha_i \\Delta(f(x_i),y_i), \\qquad \\alpha_i = \\left\\{\n",
    "\\begin{array}{ll}\n",
    "1 & \\text{si } y_i \\in \\text{classe majoritaire}\\\\\n",
    "B>1 & \\text{si } y_i \\in \\text{classe minoritaire}\\\\\n",
    "\\end{array} \\right.$$\n",
    "<BR>\n",
    "   $\\Rightarrow$ Les SVM et d'autres approches sklearn possèdent des arguments pour régler $B$ ou $1/B$... Ces arguments sont utiles mais pas toujours suffisant.\n",
    "1. Courbe ROC et modification du biais. Une fois la fonction $\\hat y = f(x)$ apprise, il est possible de la *bidouiller* a posteriori: si toutes les prédictions $\\hat y$ sont dans une classe, on va introduire $b$ dans $\\hat y = f(x) + b$ et le faire varier jusqu'à ce qu'un des points change de classe. On peut ensuite aller de plus en plus loin.\n",
    "Le calcul de l'ensemble des scores associés à cette approche mène directement à la courbe ROC.\n",
    "\n",
    "**Note:** certains classifieurs sont intrinsèquement plus résistante au problème d'équilibrage, c'est par exemple le cas des techniques de gradient boosting que vous verrez l'an prochain."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3) Post-processing sur les données Président\n",
    "\n",
    "Pour la tâche de reconnaissance de locuteur, des phrases successives sont souvent associés à un même locuteur. Voir par exemples les 100 premiers labels de la base d'apprentissage. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x1c0be6f6430>]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fname = \"./datasets/AFDpresidentutf8/corpus.tache1.learn.utf8\"\n",
    "alltxts,alllabs = load_pres(fname)\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(list(range(len(alllabs[0:100]))),alllabs[0:100])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Une méthode de post-traitement pour améliorer les résultats consistent à lisser les résultats de la prédictions d'une phrases par les prédictions voisines, en utilisant par exemple une convolution par une filtre Gaussien. Compléter la fonction ci-dessous et tester l'impact de ce lissage sur les performances.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gaussian_smoothing(pred, size):\n",
    "     # LISSAGE par un filtre Gaussien de taille size - vous pouvez utiliser np.convolve \n",
    "    return 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## 4) Estimer les performances de généralisation d'une méthodes\n",
    "**Ce sera l'enjeu principal du projet : vous disposez d'un ensemble de données, et vous évaluerez les performances sur un ensemble de test auquel vous n'avez pas accès. Il faut donc être capable d'estimer les performances de généralisation du modèles à partir des données d'entraînement.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Avant de lancer de grandes expériences, il faut se construire une base de travail solide en étudiant les questions suivantes:\n",
    "\n",
    "- Combien de temps ça prend d'apprendre un classifieur NB/SVM/RegLog sur ces données en fonction de la taille du vocabulaire?\n",
    "- La validation croisée est-elle nécessaire? Est ce qu'on obtient les mêmes résultats avec un simple *split*?\n",
    "- La validation croisée est-elle stable? A partir de combien de fold (travailler avec différentes graines aléatoires et faire des statistiques basiques)?"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
